lemmy:
  # The Lemmy instance to scrape (without https://)
  instance: "lemmy.ml"

  # Your Lemmy account credentials (required for authentication)
  username: "your_username"
  password: "your_password"

  # List of communities to scrape (e.g., ["technology", "linux", "programming"])
  # Leave empty [] to scrape from the instance's "hot" page
  communities: []

storage:
  # Base directory where media will be saved
  # Files will be organized in subdirectories by community name
  base_directory: "./downloads"

database:
  # Path to SQLite database file for tracking scraped media
  path: "./lemmy-scraper.db"

scraper:
  # Maximum number of posts to scrape per run (total across all pages)
  # Note: Lemmy API maximum is 50 posts per request, but pagination can fetch more
  max_posts_per_run: 50

  # Idempotency settings - choose your strategy:

  # Stop when encountering previously seen posts (default: true)
  # Uses seen_posts_threshold to determine when to stop
  stop_at_seen_posts: true

  # Skip seen posts but continue scraping (default: false)
  # Useful for non-chronological sorts like "TopWeek"
  skip_seen_posts: false

  # Number of consecutive seen posts before stopping (default: 5)
  # Only used when stop_at_seen_posts is true
  seen_posts_threshold: 5

  # Enable pagination to fetch more than 50 posts (default: false)
  # When enabled, makes multiple API requests to get up to max_posts_per_run
  enable_pagination: false

  # Sort type: "Hot", "New", "TopDay", "TopWeek", "TopMonth", "TopYear", "TopAll", "Active"
  sort_type: "Hot"

  # Media types to download
  include_images: true
  include_videos: true
  include_other_media: true

run_mode:
  # Run mode: "once" (run once and exit) or "continuous" (run on interval)
  mode: "once"

  # Interval for continuous mode (e.g., "5m", "1h", "30m")
  # Only used when mode is "continuous"
  interval: "30m"

web_server:
  # Enable the web UI for browsing downloaded media (default: false)
  enabled: false

  # Host to bind the web server to (default: "localhost")
  # Use "0.0.0.0" to allow external access
  host: "localhost"

  # Port for the web server (default: 8080)
  port: 8080

thumbnails:
  # Enable thumbnail generation for faster web UI loading (default: true)
  enabled: true

  # Maximum thumbnail dimensions (maintains aspect ratio)
  max_width: 400
  max_height: 400

  # JPEG quality for thumbnails (1-100, higher is better quality)
  quality: 85

  # Directory to store thumbnails
  directory: "./thumbnails"

  # Method for generating video thumbnails (ffmpeg required)
  video_method: "ffmpeg"

recognition:
  # Enable AI-powered image recognition and classification (default: false)
  enabled: false

  # Recognition provider: "ollama", "huggingface", or "gradio_space"
  # - ollama: Runs locally, requires Ollama installed with a vision model
  # - huggingface: Uses HuggingFace Inference API, requires API key
  # - gradio_space: Uses your own HuggingFace Gradio Space for custom models
  provider: "ollama"

  # === Ollama Settings (when provider: "ollama") ===
  # Ollama API URL
  ollama_url: "http://localhost:11434"

  # === HuggingFace Settings (when provider: "huggingface") ===
  # HuggingFace API key - Get yours at: https://huggingface.co/settings/tokens
  # IMPORTANT: Keep this secret! Consider using environment variables:
  #   huggingface_api_key: "${HUGGINGFACE_API_KEY}"
  huggingface_api_key: ""

  # === Gradio Space Settings (when provider: "gradio_space") ===
  # URL of your Gradio Space (e.g., https://username-space-name.hf.space)
  # This allows you to use custom vision models hosted on HuggingFace Spaces
  gradio_space_url: ""

  # Optional API key for private Gradio Spaces
  # Leave empty for public Spaces
  gradio_space_api_key: ""

  # Model to use for image recognition (provider-specific)
  #
  # Ollama models (install with: ollama pull <model>):
  #   - "llama3.2-vision:11b" - Best balance (recommended)
  #   - "llama3.2-vision:90b" - Most accurate (requires powerful GPU)
  #   - "llava:13b" - Good alternative
  #
  # HuggingFace models (see HUGGINGFACE_SETUP.md for details):
  #   - "Salesforce/blip-image-captioning-base" - Fast, good balance (default)
  #   - "Salesforce/blip-image-captioning-large" - Very detailed captions
  #   - "Salesforce/blip2-opt-2.7b" - Most advanced, uncensored
  #   - "microsoft/git-large-coco" - Fast alternative
  #
  # Gradio Space: Not used - the Space URL determines the model
  model: "llama3.2-vision:latest"

  # Automatically create tags from AI classifications
  # Tags are generated from detected objects, categories, and characteristics
  auto_tag: true

  # Enable NSFW content detection
  # - Ollama: Uses uncensored prompts for detailed NSFW tagging
  # - HuggingFace: Uses specialized NSFW model (Falconsai/nsfw_image_detection)
  # Provides maturity levels: sfw, suggestive, artistic, explicit
  nsfw_detection: false

  # Minimum confidence threshold for auto-tagging (0.0-1.0)
  # Lower values = more tags, higher values = only confident tags
  confidence_threshold: 0.6

search:
  # Rebuild the full-text search index on startup (default: false)
  # Only needed if search results seem incorrect
  rebuild_index: false
